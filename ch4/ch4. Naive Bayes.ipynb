{
 "metadata": {
  "name": "",
  "signature": "sha256:2bbf74078c4a9171107569e629e554ce6c191fa33b1ea0f634839a605ea16835"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import bayes\n",
      "\n",
      "# \uc911\ubcf5\ub418\ub294 \ub2e8\uc5b4 \uc81c\uc678\n",
      "listOPosts, listClasses = bayes.loadDataSet()\n",
      "myVocabList = bayes.createVocabList(listOPosts)\n",
      "myVocabList "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "['cute',\n",
        " 'love',\n",
        " 'help',\n",
        " 'garbage',\n",
        " 'quit',\n",
        " 'I',\n",
        " 'problems',\n",
        " 'is',\n",
        " 'park',\n",
        " 'stop',\n",
        " 'flea',\n",
        " 'dalmation',\n",
        " 'licks',\n",
        " 'food',\n",
        " 'not',\n",
        " 'him',\n",
        " 'buying',\n",
        " 'posting',\n",
        " 'has',\n",
        " 'worthless',\n",
        " 'ate',\n",
        " 'to',\n",
        " 'maybe',\n",
        " 'please',\n",
        " 'dog',\n",
        " 'how',\n",
        " 'stupid',\n",
        " 'so',\n",
        " 'take',\n",
        " 'mr',\n",
        " 'steak',\n",
        " 'my']"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bayes.setOfWords2Vec(myVocabList, listOPosts[0])\n",
      "\n",
      "bayes.setOfWords2Vec(myVocabList, listOPosts[3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "[0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0]"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \ub098\uc774\ube0c \ubca0\uc774\uc2a4 \ubd84\ub958\uae30 \ud6c8\ub828 \ud568\uc218\n",
      "\n",
      "def trainNB0(trainMatrix,trainCategory):\n",
      "    numTrainDocs = len(trainMatrix)\n",
      "    numWords = len(trainMatrix[0])\n",
      "    pAbusive = sum(trainCategory)/float(numTrainDocs)\n",
      "    p0Num = ones(numWords); p1Num = ones(numWords)      #change to ones() \n",
      "    p0Denom = 2.0; p1Denom = 2.0                        #change to 2.0\n",
      "    for i in range(numTrainDocs):\n",
      "        if trainCategory[i] == 1:\n",
      "            p1Num += trainMatrix[i]\n",
      "            p1Denom += sum(trainMatrix[i])\n",
      "        else:\n",
      "            p0Num += trainMatrix[i]\n",
      "            p0Denom += sum(trainMatrix[i])\n",
      "    p1Vect = log(p1Num/p1Denom)          #change to log()\n",
      "    p0Vect = log(p0Num/p0Denom)          #change to log()\n",
      "    return p0Vect,p1Vect,pAbusive"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numpy import *\n",
      "reload(bayes)\n",
      "listOPosts, listClasses = bayes.loadDataSet()\n",
      "myVocabList = bayes.createVocabList(listOPosts)\n",
      "trainMat = []\n",
      "for postinDoc in listOPosts:\n",
      "    trainMat.append(bayes.setOfWords2Vec(myVocabList, postinDoc))\n",
      "    \n",
      "p0V, p1V, pAb = bayes.trainNB0(trainMat,listClasses)\n",
      "\n",
      "pAb\n",
      "\n",
      "p0V\n",
      "\n",
      "p1V"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "array([-3.04452244, -3.04452244, -3.04452244, -2.35137526, -2.35137526,\n",
        "       -3.04452244, -3.04452244, -3.04452244, -2.35137526, -2.35137526,\n",
        "       -3.04452244, -3.04452244, -3.04452244, -2.35137526, -2.35137526,\n",
        "       -2.35137526, -2.35137526, -2.35137526, -3.04452244, -1.94591015,\n",
        "       -3.04452244, -2.35137526, -2.35137526, -3.04452244, -1.94591015,\n",
        "       -3.04452244, -1.65822808, -3.04452244, -2.35137526, -3.04452244,\n",
        "       -3.04452244, -3.04452244])"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \ub098\uc774\ube0c \ubca0\uc774\uc2a4 \ubd84\ub958 \ud568\uc218\n",
      "\n",
      "def classifyNB(vec2Classify, p0Vec, p1Vec, pClass1):\n",
      "    p1 = sum(vec2Classify * p1Vec) + log(pClass1)    #element-wise mult\n",
      "    p0 = sum(vec2Classify * p0Vec) + log(1.0 - pClass1)\n",
      "    if p1 > p0:\n",
      "        return 1\n",
      "    else: \n",
      "        return 0\n",
      "\n",
      "def testingNB():\n",
      "    listOPosts,listClasses = loadDataSet()\n",
      "    myVocabList = createVocabList(listOPosts)\n",
      "    trainMat=[]\n",
      "    for postinDoc in listOPosts:\n",
      "        trainMat.append(setOfWords2Vec(myVocabList, postinDoc))\n",
      "    p0V,p1V,pAb = trainNB0(array(trainMat),array(listClasses))\n",
      "    testEntry = ['love', 'my', 'dalmation']\n",
      "    thisDoc = array(setOfWords2Vec(myVocabList, testEntry))\n",
      "    print testEntry,'classified as: ',classifyNB(thisDoc,p0V,p1V,pAb)\n",
      "    testEntry = ['stupid', 'garbage']\n",
      "    thisDoc = array(setOfWords2Vec(myVocabList, testEntry))\n",
      "    print testEntry,'classified as: ',classifyNB(thisDoc,p0V,p1V,pAb)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(bayes)\n",
      "bayes.testingNB()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['love', 'my', 'dalmation'] classified as:  0\n",
        "['stupid', 'garbage'] classified as:  1\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \ub098\uc774\ube0c \ubca0\uc774\uc2a4 \uc911\ubcf5 \ub2e8\uc5b4 \ubaa8\ub378\n",
      "\n",
      "def bagOfWords2VecMN(vocabList, inputSet):\n",
      "    returnVec = [0]*len(vocabList)\n",
      "    for word in inputSet:\n",
      "        if word in vocabList:\n",
      "            returnVec[vocabList.index(word)] += 1\n",
      "    return returnVec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# .\uc774 \ub2e8\uc5b4\uc758 \uc77c\ubd80\ub85c \uac04\uc8fc\ub428\n",
      "\n",
      "mySent = 'This book is the best book on Python or M.L. I have ever laid eyes upon.'\n",
      "mySent.split()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "['This',\n",
        " 'book',\n",
        " 'is',\n",
        " 'the',\n",
        " 'best',\n",
        " 'book',\n",
        " 'on',\n",
        " 'Python',\n",
        " 'or',\n",
        " 'M.L.',\n",
        " 'I',\n",
        " 'have',\n",
        " 'ever',\n",
        " 'laid',\n",
        " 'eyes',\n",
        " 'upon.']"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# .\uc774 \ub2e8\uc5b4\uc758 \uc77c\ubd80\ub85c \uac04\uc8fc\ub418\uc9c0 \uc54a\uc74c\n",
      "\n",
      "import re\n",
      "regEx = re.compile('\\\\W*')\n",
      "listOfTokens = regEx.split(mySent)\n",
      "listOfTokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "['This',\n",
        " 'book',\n",
        " 'is',\n",
        " 'the',\n",
        " 'best',\n",
        " 'book',\n",
        " 'on',\n",
        " 'Python',\n",
        " 'or',\n",
        " 'M',\n",
        " 'L',\n",
        " 'I',\n",
        " 'have',\n",
        " 'ever',\n",
        " 'laid',\n",
        " 'eyes',\n",
        " 'upon',\n",
        " '']"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \uae38\uc774\uac00 0\ubcf4\ub2e4 \ud070 \uac83\ub9cc\uc744 \ubc18\ud658\n",
      "\n",
      "[tok for tok in listOfTokens if len(tok) > 0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "['This',\n",
        " 'book',\n",
        " 'is',\n",
        " 'the',\n",
        " 'best',\n",
        " 'book',\n",
        " 'on',\n",
        " 'Python',\n",
        " 'or',\n",
        " 'M',\n",
        " 'L',\n",
        " 'I',\n",
        " 'have',\n",
        " 'ever',\n",
        " 'laid',\n",
        " 'eyes',\n",
        " 'upon']"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \uc2a4\ud2b8\ub9c1\uc744 \ubaa8\ub450 \uc18c\ubb38\uc790\ub85c \ubc14\uafc8 => lower() / \ub300\ubb38\uc790\ub85c \ubc14\uafc8 => upper()\n",
      "\n",
      "[tok.lower() for tok in listOfTokens if len(tok) > 0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "['this',\n",
        " 'book',\n",
        " 'is',\n",
        " 'the',\n",
        " 'best',\n",
        " 'book',\n",
        " 'on',\n",
        " 'python',\n",
        " 'or',\n",
        " 'm',\n",
        " 'l',\n",
        " 'i',\n",
        " 'have',\n",
        " 'ever',\n",
        " 'laid',\n",
        " 'eyes',\n",
        " 'upon']"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "emailText = open('email/ham/6.txt').read()\n",
      "listOfTokens = regEx.split(emailText)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \ud30c\uc77c \uad6c\ubb38 \ubd84\uc11d\uacfc \uc804\uccb4 \uc2a4\ud338 \uac80\uc0ac \ud568\uc218\n",
      "\n",
      "def textParse(bigString):    #input is big string, #output is word list\n",
      "    import re\n",
      "    listOfTokens = re.split(r'\\W*', bigString)\n",
      "    return [tok.lower() for tok in listOfTokens if len(tok) > 2] \n",
      "    \n",
      "def spamTest():\n",
      "    docList=[]; classList = []; fullText =[]\n",
      "    for i in range(1,26):\n",
      "        wordList = textParse(open('email/spam/%d.txt' % i).read())\n",
      "        docList.append(wordList)\n",
      "        fullText.extend(wordList)\n",
      "        classList.append(1)\n",
      "        wordList = textParse(open('email/ham/%d.txt' % i).read())\n",
      "        docList.append(wordList)\n",
      "        fullText.extend(wordList)\n",
      "        classList.append(0)\n",
      "    vocabList = createVocabList(docList)#create vocabulary\n",
      "    trainingSet = range(50); testSet=[]           #create test set\n",
      "    for i in range(10):\n",
      "        randIndex = int(random.uniform(0,len(trainingSet)))\n",
      "        testSet.append(trainingSet[randIndex])\n",
      "        del(trainingSet[randIndex])  \n",
      "    trainMat=[]; trainClasses = []\n",
      "    for docIndex in trainingSet:#train the classifier (get probs) trainNB0\n",
      "        trainMat.append(bagOfWords2VecMN(vocabList, docList[docIndex]))\n",
      "        trainClasses.append(classList[docIndex])\n",
      "    p0V,p1V,pSpam = trainNB0(array(trainMat),array(trainClasses))\n",
      "    errorCount = 0\n",
      "    for docIndex in testSet:        #classify the remaining items\n",
      "        wordVector = bagOfWords2VecMN(vocabList, docList[docIndex])\n",
      "        if classifyNB(array(wordVector),p0V,p1V,pSpam) != classList[docIndex]:\n",
      "            errorCount += 1\n",
      "            print \"classification error\",docList[docIndex]\n",
      "    print 'the error rate is: ',float(errorCount)/len(testSet)\n",
      "    #return vocabList,fullText"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \uc784\uc758\ub85c \uc120\ud0dd\ub41c 10\uac1c\uc758 \uc774\uba54\uc77c\ub85c\ubd80\ud130\uc758 \uc624\ub958\uc728\n",
      "bayes.spamTest()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "classification error ['yay', 'you', 'both', 'doing', 'fine', 'working', 'mba', 'design', 'strategy', 'cca', 'top', 'art', 'school', 'new', 'program', 'focusing', 'more', 'right', 'brained', 'creative', 'and', 'strategic', 'approach', 'management', 'the', 'way', 'done', 'today']\n",
        "the error rate is:  0.1\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named feedparser",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-1-c598ee460a82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mfeedparser\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mny\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeedparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http://newyork.craigslist.org/stp/index.rss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mImportError\u001b[0m: No module named feedparser"
       ]
      }
     ],
     "prompt_number": 1
    }
   ],
   "metadata": {}
  }
 ]
}