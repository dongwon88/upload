{
 "metadata": {
  "name": "",
  "signature": "sha256:6e750b8dc2d2bebc1c0a425ce65219db254eeac246123d1736667deb3465c5b9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \ub85c\uc9c0\uc2a4\ud2f1 \ud68c\uadc0 \uae30\uc6b8\uae30 \uc0c1\uc2b9 \ucd5c\uc801\ud654 \ud568\uc218\n",
      "\n",
      "from numpy import *\n",
      "\n",
      "def loadDataSet():\n",
      "    dataMat = []; labelMat = []\n",
      "    fr = open('testSet.txt')\n",
      "    for line in fr.readlines():\n",
      "        lineArr = line.strip().split()\n",
      "        dataMat.append([1.0, float(lineArr[0]), float(lineArr[1])])\n",
      "        labelMat.append(int(lineArr[2]))\n",
      "    return dataMat,labelMat\n",
      "\n",
      "def sigmoid(inX):\n",
      "    return 1.0/(1+exp(-inX))\n",
      "\n",
      "def gradAscent(dataMatIn, classLabels):\n",
      "    dataMatrix = mat(dataMatIn)             #convert to NumPy matrix\n",
      "    labelMat = mat(classLabels).transpose() #convert to NumPy matrix\n",
      "    m,n = shape(dataMatrix)\n",
      "    alpha = 0.001\n",
      "    maxCycles = 500\n",
      "    weights = ones((n,1))\n",
      "    for k in range(maxCycles):              #heavy on matrix operations\n",
      "        h = sigmoid(dataMatrix*weights)     #matrix mult\n",
      "        error = (labelMat - h)              #vector subtraction\n",
      "        weights = weights + alpha * dataMatrix.transpose()* error #matrix mult\n",
      "    return weights"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import logRegres\n",
      "dataArr, labelMat = logRegres.loadDataSet()\n",
      "logRegres.gradAscent(dataArr, labelMat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "matrix([[ 4.12414349],\n",
        "        [ 0.48007329],\n",
        "        [-0.6168482 ]])"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plotBestFit(weights):\n",
      "    import matplotlib.pyplot as plt\n",
      "    dataMat,labelMat=loadDataSet()\n",
      "    dataArr = array(dataMat)\n",
      "    n = shape(dataArr)[0] \n",
      "    xcord1 = []; ycord1 = []\n",
      "    xcord2 = []; ycord2 = []\n",
      "    for i in range(n):\n",
      "        if int(labelMat[i])== 1:\n",
      "            xcord1.append(dataArr[i,1]); ycord1.append(dataArr[i,2])\n",
      "        else:\n",
      "            xcord2.append(dataArr[i,1]); ycord2.append(dataArr[i,2])\n",
      "    fig = plt.figure()\n",
      "    ax = fig.add_subplot(111)\n",
      "    ax.scatter(xcord1, ycord1, s=30, c='red', marker='s')\n",
      "    ax.scatter(xcord2, ycord2, s=30, c='green')\n",
      "    x = arange(-3.0, 3.0, 0.1)\n",
      "    y = (-weights[0]-weights[1]*x)/weights[2]\n",
      "    ax.plot(x, y)\n",
      "    plt.xlabel('X1'); plt.ylabel('X2');\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weights = logRegres.gradAscent(dataArr, labelMat)\n",
      "logRegres.plotBestFit(weights.getA())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \ud655\ub960 \uae30\uc6b8\uae30 \uc0c1\uc2b9\n",
      "\n",
      "def stocGradAscent0(dataMatrix, classLabels):\n",
      "    m,n = shape(dataMatrix)\n",
      "    alpha = 0.01\n",
      "    weights = ones(n)   #initialize to all ones\n",
      "    for i in range(m):\n",
      "        h = sigmoid(sum(dataMatrix[i]*weights))\n",
      "        error = classLabels[i] - h\n",
      "        weights = weights + alpha * error * dataMatrix[i]\n",
      "    return weights"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numpy import *\n",
      "dataArr, labelMat = logRegres.loadDataSet()\n",
      "weights = logRegres.stocGradAscent0(array(dataArr), labelMat)\n",
      "logRegres.plotBestFit(weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \uc218\uc815\ub41c \ud655\ub960 \uae30\uc6b8\uae30 \uc0c1\uc2b9 \uc54c\uace0\ub9ac\uc998\n",
      "\n",
      "def stocGradAscent1(dataMatrix, classLabels, numIter=150):\n",
      "    m,n = shape(dataMatrix)\n",
      "    weights = ones(n)   #initialize to all ones\n",
      "    for j in range(numIter):\n",
      "        dataIndex = range(m)\n",
      "        for i in range(m):\n",
      "            alpha = 4/(1.0+j+i)+0.0001    #apha decreases with iteration, does not \n",
      "            randIndex = int(random.uniform(0,len(dataIndex)))#go to 0 because of the constant\n",
      "            h = sigmoid(sum(dataMatrix[randIndex]*weights))\n",
      "            error = classLabels[randIndex] - h\n",
      "            weights = weights + alpha * error * dataMatrix[randIndex]\n",
      "            del(dataIndex[randIndex])\n",
      "    return weights"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataArr, labelMat = logRegres.loadDataSet()\n",
      "weights = logRegres.stocGradAscent1(array(dataArr), labelMat)\n",
      "logRegres.plotBestFit(weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weights = logRegres.stocGradAscent1(array(dataArr), labelMat, 500)\n",
      "logRegres.plotBestFit(weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def classifyVector(inX, weights):\n",
      "    prob = sigmoid(sum(inX*weights))\n",
      "    if prob > 0.5: return 1.0\n",
      "    else: return 0.0\n",
      "\n",
      "def colicTest():\n",
      "    frTrain = open('horseColicTraining.txt'); frTest = open('horseColicTest.txt')\n",
      "    trainingSet = []; trainingLabels = []\n",
      "    for line in frTrain.readlines():\n",
      "        currLine = line.strip().split('\\t')\n",
      "        lineArr =[]\n",
      "        for i in range(21):\n",
      "            lineArr.append(float(currLine[i]))\n",
      "        trainingSet.append(lineArr)\n",
      "        trainingLabels.append(float(currLine[21]))\n",
      "    trainWeights = stocGradAscent1(array(trainingSet), trainingLabels, 1000)\n",
      "    errorCount = 0; numTestVec = 0.0\n",
      "    for line in frTest.readlines():\n",
      "        numTestVec += 1.0\n",
      "        currLine = line.strip().split('\\t')\n",
      "        lineArr =[]\n",
      "        for i in range(21):\n",
      "            lineArr.append(float(currLine[i]))\n",
      "        if int(classifyVector(array(lineArr), trainWeights))!= int(currLine[21]):\n",
      "            errorCount += 1\n",
      "    errorRate = (float(errorCount)/numTestVec)\n",
      "    print \"the error rate of this test is: %f\" % errorRate\n",
      "    return errorRate\n",
      "\n",
      "def multiTest():\n",
      "    numTests = 10; errorSum=0.0\n",
      "    for k in range(numTests):\n",
      "        errorSum += colicTest()\n",
      "    print \"after %d iterations the average error rate is: %f\" % (numTests, errorSum/float(numTests))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logRegres.multiTest()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "the error rate of this test is: 0.358209\n",
        "the error rate of this test is: 0.388060"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "the error rate of this test is: 0.402985"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "the error rate of this test is: 0.283582"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "the error rate of this test is: 0.268657"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "the error rate of this test is: 0.313433"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "the error rate of this test is: 0.343284"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "the error rate of this test is: 0.343284"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "the error rate of this test is: 0.358209"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "the error rate of this test is: 0.358209"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "after 10 iterations the average error rate is: 0.341791\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "logRegres.py:18: RuntimeWarning: overflow encountered in exp\n",
        "  return 1.0/(1+exp(-inX))\n"
       ]
      }
     ],
     "prompt_number": 11
    }
   ],
   "metadata": {}
  }
 ]
}